{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import statistics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oresults_path = '../predicted-results/original/nbins-10'\n",
    "mresults_path = '../predicted-results/mixed5050/nbins-10'\n",
    "eresults_path = '../predicted-results/everything/nbins-10'\n",
    "\n",
    "omodels_path = '../models/original'\n",
    "mmodels_path = '../models/mixed5050/nbins-10'\n",
    "emodels_path = '../models/everything/nbins-10'\n",
    "\n",
    "test_sets = ['5050', '2575', 'everything']\n",
    "\n",
    "mpoints = [100, 200, 300, 500, 1000, 2000, 2500, 'all']\n",
    "epoints = [100, 200, 300, 500, 1000, 2000, 2500, 4000, 6000, 'all']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider 5050 models and everything models at the 2500 mark \n",
    "m5models = dict()\n",
    "emodels = dict()\n",
    "omodels = dict()\n",
    "# 5050 model\n",
    "for tset in ['5050', '2575', 'everything']:\n",
    "    m5models[tset] = dict()\n",
    "    emodels[tset] = dict()\n",
    "    omodels[tset] = dict()\n",
    "    \n",
    "    '''First load the original models'''\n",
    "    for target in ['COF', 'intercept']:\n",
    "        with open(f'{omodels_path}/{target}.pickle', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        with open(f'{omodels_path}/{target}.pickle', 'rb') as f:\n",
    "            features = pickle.load(f)\n",
    "        with open(f'{oresults_path}/{target}_on_{tset}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "        omodels[tset][target] = {'model': model,\n",
    "                                 'features': features,\n",
    "                                 'data': data,\n",
    "                                 'n_train': len(model.oob_prediction_),\n",
    "                                 'r_square': data[target]['r_square']}\n",
    "        \n",
    "    '''Then load the mixed5050 models'''\n",
    "    for point in mpoints:\n",
    "        for i in range(5):\n",
    "            for target in ['COF', 'intercept']:\n",
    "                with open(f'{mmodels_path}/set_{i}/{target}_{point}.pickle', 'rb') as f:\n",
    "                    model = pickle.load(f)\n",
    "                with open(f'{mmodels_path}/set_{i}/{target}_{point}.ptxt', 'rb') as f:\n",
    "                    features = pickle.load(f)\n",
    "                with open(f'{mresults_path}/set_{i}/{target}_{point}_on_{tset}.json', 'r') as f :\n",
    "                    data = json.load(f)\n",
    "                if i == 0:\n",
    "                    if not m5models[tset].get(target):\n",
    "                        m5models[tset][target] = dict()\n",
    "                    m5models[tset][target][point] = {\n",
    "                      'model': model,\n",
    "                      'features': features,\n",
    "                      'data': [data],\n",
    "                      'n_train': len(model.oob_prediction_),\n",
    "                      'r_square': [data[target]['r_square']]}\n",
    "                else:\n",
    "                    m5models[tset][target][point]['data'].append(data)\n",
    "                    m5models[tset][target][point]['r_square'].append(data[target]['r_square'])\n",
    "                    \n",
    "    '''Finally load the combined models'''\n",
    "    for point in epoints:\n",
    "        # Lastly deal with the everything models\n",
    "        for i in range(5):\n",
    "            for target in ['COF', 'intercept']:\n",
    "                with open(f'{emodels_path}/set_{i}/{target}_{point}.pickle', 'rb') as f:\n",
    "                    model = pickle.load(f)\n",
    "                with open(f'{emodels_path}/set_{i}/{target}_{point}.ptxt', 'rb') as f:\n",
    "                    features = pickle.load(f)\n",
    "                with open(f'{eresults_path}/set_{i}/{target}_{point}_on_{tset}.json', 'r') as f :\n",
    "                    data = json.load(f)\n",
    "                if i == 0:\n",
    "                    if not emodels[tset].get(target):\n",
    "                        emodels[tset][target] = dict()\n",
    "                    emodels[tset][target][point] = {\n",
    "                      'model': model,\n",
    "                      'features': features,\n",
    "                      'data': [data],\n",
    "                      'n_train': len(model.oob_prediction_),\n",
    "                      'r_square': [data[target]['r_square']]}\n",
    "                else:\n",
    "                    emodels[tset][target][point]['data'].append(data)\n",
    "                    emodels[tset][target][point]['r_square'].append(data[target]['r_square'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tset in ['5050', '2575', 'everything']:\n",
    "    for point in mpoints:\n",
    "        for target in ['COF', 'intercept']:\n",
    "\n",
    "            m5models[tset][target][point]['ave_data'] = dict() \n",
    "            m5models[tset][target][point]['std_data'] = dict()\n",
    "            m5models[tset][target][point]['ratio-to-simulated'] = dict()\n",
    "            m5models[tset][target][point]['error'] = dict()\n",
    "            for j in m5models[tset][target][point]['data'][0][target]:\n",
    "                for i in range(5):\n",
    "                    if i==0 and j!='r_square':\n",
    "                        m5models[tset][target][point]['ave_data'][j] = [m5models[tset][target][point]['data'][i][target][j][f'predicted-{target}']]\n",
    "                    elif j!='r_square':\n",
    "                        m5models[tset][target][point]['ave_data'][j].append(m5models[tset][target][point]['data'][i][target][j][f'predicted-{target}'])\n",
    "                if j!='r_square':\n",
    "                    m5models[tset][target][point]['std_data'][j] = statistics.stdev(m5models[tset][target][point]['ave_data'][j])\n",
    "                    m5models[tset][target][point]['ave_data'][j] = statistics.mean(m5models[tset][target][point]['ave_data'][j])\n",
    "                    m5models[tset][target][point]['ratio-to-simulated'][j] = m5models[tset][target][point]['ave_data'][j]/m5models[tset][target][point]['data'][i][target][j][f'simulated-{target}']\n",
    "                    m5models[tset][target][point]['error'][j] = m5models[tset][target][point]['ave_data'][j] - m5models[tset][target][point]['data'][i][target][j][f'simulated-{target}']\n",
    "    for point in epoints:\n",
    "        for target in ['COF', 'intercept']:\n",
    "            emodels[tset][target][point]['ave_data'] = dict()\n",
    "            emodels[tset][target][point]['std_data'] = dict()\n",
    "            emodels[tset][target][point]['ratio-to-simulated'] = dict()\n",
    "            emodels[tset][target][point]['error'] = dict()\n",
    "            for j in emodels[tset][target][point]['data'][0][target]:\n",
    "                for i in range(5):\n",
    "                    if i==0 and j!='r_square':\n",
    "                        emodels[tset][target][point]['ave_data'][j] = [emodels[tset][target][point]['data'][i][target][str(j)][f'predicted-{target}']]\n",
    "                    elif j!='r_square':\n",
    "                        emodels[tset][target][point]['ave_data'][j].append(emodels[tset][target][point]['data'][i][target][str(j)][f'predicted-{target}'])\n",
    "                if j!='r_square':\n",
    "                    emodels[tset][target][point]['std_data'][j] = statistics.stdev(emodels[tset][target][point]['ave_data'][j])\n",
    "                    emodels[tset][target][point]['ave_data'][j] = statistics.mean(emodels[tset][target][point]['ave_data'][j])\n",
    "                    emodels[tset][target][point]['ratio-to-simulated'][j] = emodels[tset][target][point]['ave_data'][j]/emodels[tset][target][point]['data'][i][target][j][f'simulated-{target}']\n",
    "                    emodels[tset][target][point]['error'][j] = emodels[tset][target][point]['ave_data'][j] - emodels[tset][target][point]['data'][i][target][j][f'simulated-{target}']\n",
    "    for target in ['COF', 'intercept']:\n",
    "        omodels[tset][target]['ratio-to-simulated'] = dict()\n",
    "        omodels[tset][target]['error'] = dict()\n",
    "        for j in omodels[tset][target]['data'][target]:\n",
    "            if j!='r_square':\n",
    "                omodels[tset][target]['ratio-to-simulated'][j] = omodels[tset][target]['data'][target][j][f'predicted-{target}']/omodels[tset][target]['data'][target][j][f'simulated-{target}']\n",
    "                omodels[tset][target]['error'][j] = omodels[tset][target]['data'][target][j][f'predicted-{target}'] - omodels[tset][target]['data'][target][j][f'simulated-{target}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
