{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d239ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle \n",
    "import pandas \n",
    "import numpy as np\n",
    "import scipy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28613fc7",
   "metadata": {},
   "source": [
    "## Feature vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e079b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature-clusters.json\", \"r\") as f:\n",
    "    full_features = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0628ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features = list()\n",
    "for group in full_features:\n",
    "    for feature in full_features[group]:\n",
    "        total_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83138c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8bff4f",
   "metadata": {},
   "source": [
    "## Reduced features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11e6e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oresults_path = '../predicted-results/original/nbins-10'\n",
    "mresults_path = '../predicted-results/mixed5050/nbins-10'\n",
    "eresults_path = '../predicted-results/everything/nbins-10'\n",
    "\n",
    "omodels_path = '../models/original'\n",
    "mmodels_path = '../models/mixed5050/nbins-10'\n",
    "emodels_path = '../models/everything/nbins-10'\n",
    "\n",
    "test_sets = ['5050', '2575', 'everything']\n",
    "\n",
    "mpoints = [100, 200, 300, 500, 1000, 1500, 2000, 2500, 'all']\n",
    "epoints = [100, 200, 300, 500, 1000, 1500, 2000, 2500, 4000, 6000, 'all']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bfb1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider 5050 models and everything models at the 2500 mark \n",
    "m5models = dict()\n",
    "emodels = dict()\n",
    "omodels = dict()\n",
    "for tset in ['5050', '2575', 'everything']:\n",
    "    m5models[tset] = dict()\n",
    "    emodels[tset] = dict()\n",
    "    omodels[tset] = dict()\n",
    "    \n",
    "    '''First load the original models'''\n",
    "    for target in ['COF', 'intercept']:\n",
    "        with open(f'{omodels_path}/{target}.pickle', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        with open(f'{omodels_path}/{target}.ptxt', 'rb') as f:\n",
    "            features = pickle.load(f)\n",
    "        with open(f'{oresults_path}/{target}_on_{tset}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "        omodels[tset][target] = {'model': model,\n",
    "                                 'features': features,\n",
    "                                 'data': data,\n",
    "                                 'n_train': len(model.oob_prediction_),\n",
    "                                 'r_square': data[target]['r_square']}\n",
    "        \n",
    "    '''Then load the mixed5050 models'''\n",
    "    for point in mpoints:\n",
    "        for i in range(5):\n",
    "            for target in ['COF', 'intercept']:\n",
    "                with open(f'{mmodels_path}/set_{i}/{target}_{point}.pickle', 'rb') as f:\n",
    "                    model = pickle.load(f)\n",
    "                with open(f'{mmodels_path}/set_{i}/{target}_{point}.ptxt', 'rb') as f:\n",
    "                    features = pickle.load(f)\n",
    "                with open(f'{mresults_path}/set_{i}/{target}_{point}_on_{tset}.json', 'r') as f :\n",
    "                    data = json.load(f)\n",
    "                if i == 0:\n",
    "                    if not m5models[tset].get(target):\n",
    "                        m5models[tset][target] = dict()\n",
    "                    m5models[tset][target][point] = {\n",
    "                      'model': model,\n",
    "                      'features': [features],\n",
    "                      'data': [data],\n",
    "                      'n_train': len(model.oob_prediction_),\n",
    "                      'r_square': [data[target]['r_square']]}\n",
    "                else:\n",
    "                    m5models[tset][target][point]['features'].append(features)\n",
    "                    m5models[tset][target][point]['data'].append(data)\n",
    "                    m5models[tset][target][point]['r_square'].append(data[target]['r_square'])\n",
    "                    \n",
    "    '''Finally load the combined models'''\n",
    "    for point in epoints:\n",
    "        # Lastly deal with the everything models\n",
    "        for i in range(5):\n",
    "            for target in ['COF', 'intercept']:\n",
    "                with open(f'{emodels_path}/set_{i}/{target}_{point}.pickle', 'rb') as f:\n",
    "                    model = pickle.load(f)\n",
    "                with open(f'{emodels_path}/set_{i}/{target}_{point}.ptxt', 'rb') as f:\n",
    "                    features = pickle.load(f)\n",
    "                with open(f'{eresults_path}/set_{i}/{target}_{point}_on_{tset}.json', 'r') as f :\n",
    "                    data = json.load(f)\n",
    "                if i == 0:\n",
    "                    if not emodels[tset].get(target):\n",
    "                        emodels[tset][target] = dict()\n",
    "                    emodels[tset][target][point] = {\n",
    "                      'model': model,\n",
    "                      'features': [features],\n",
    "                      'data': [data],\n",
    "                      'n_train': len(model.oob_prediction_),\n",
    "                      'r_square': [data[target]['r_square']]}\n",
    "                else:\n",
    "                    emodels[tset][target][point]['features'].append(features)\n",
    "                    emodels[tset][target][point]['data'].append(data)\n",
    "                    emodels[tset][target][point]['r_square'].append(data[target]['r_square'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d371cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COF 41\n",
      "intercept 41\n"
     ]
    }
   ],
   "source": [
    "# Original model\n",
    "for target in ['COF', 'intercept']:\n",
    "    print(target, len(omodels[\"everything\"][target][\"features\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bf616eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmodels model\n",
    "mmodels_features = dict()\n",
    "for point in mpoints:\n",
    "    mmodels_features[point] = dict()\n",
    "    for target in ['COF', 'intercept']:\n",
    "        mmodels_features[point][target] = m5models[\"everything\"][target][point][\"features\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bdb94aa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "COF [41, 35, 40, 42, 39] 39.4 2.417\n",
      "intercept [40, 43, 40, 37, 39] 39.8 1.939\n",
      "\n",
      "200\n",
      "COF [40, 40, 39, 38, 39] 39.2 0.748\n",
      "intercept [38, 45, 42, 38, 37] 40.0 3.033\n",
      "\n",
      "300\n",
      "COF [41, 44, 38, 39, 40] 40.4 2.059\n",
      "intercept [38, 41, 43, 40, 35] 39.4 2.728\n",
      "\n",
      "500\n",
      "COF [40, 41, 39, 39, 42] 40.2 1.166\n",
      "intercept [37, 41, 39, 39, 38] 38.8 1.327\n",
      "\n",
      "1000\n",
      "COF [38, 39, 37, 39, 38] 38.2 0.748\n",
      "intercept [36, 37, 40, 35, 37] 37.0 1.673\n",
      "\n",
      "1500\n",
      "COF [35, 38, 35, 35, 38] 36.2 1.47\n",
      "intercept [35, 36, 35, 35, 37] 35.6 0.8\n",
      "\n",
      "2000\n",
      "COF [32, 34, 35, 33, 35] 33.8 1.166\n",
      "intercept [33, 35, 35, 34, 36] 34.6 1.02\n",
      "\n",
      "2500\n",
      "COF [33, 33, 34, 32, 32] 32.8 0.748\n",
      "intercept [33, 34, 34, 34, 36] 34.2 0.98\n",
      "\n",
      "all\n",
      "COF [32, 32, 32, 32, 32] 32.0 0.0\n",
      "intercept [34, 34, 34, 34, 34] 34.0 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for point in mpoints:\n",
    "    print(point)\n",
    "    for target in [\"COF\", \"intercept\"]:\n",
    "        n_features = [len(mmodels_features[point][target][i]) for i in range(5)]\n",
    "        print(target, n_features, np.average(n_features), round(np.std(n_features), 3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "86954bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emodels model\n",
    "emodels_features = dict()\n",
    "for point in epoints:\n",
    "    emodels_features[point] = dict()\n",
    "    for target in ['COF', 'intercept']:\n",
    "        emodels_features[point][target] = emodels[\"everything\"][target][point][\"features\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c14b29ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "COF [41, 43, 40, 45, 39] 41.6 2.154\n",
      "intercept [42, 44, 37, 39, 34] 39.2 3.544\n",
      "\n",
      "200\n",
      "COF [39, 38, 40, 38, 40] 39.0 0.894\n",
      "intercept [41, 38, 37, 38, 34] 37.6 2.245\n",
      "\n",
      "300\n",
      "COF [40, 39, 39, 37, 40] 39.0 1.095\n",
      "intercept [40, 39, 39, 37, 36] 38.2 1.47\n",
      "\n",
      "500\n",
      "COF [38, 38, 42, 40, 38] 39.2 1.6\n",
      "intercept [40, 38, 37, 36, 38] 37.8 1.327\n",
      "\n",
      "1000\n",
      "COF [40, 37, 38, 38, 37] 38.0 1.095\n",
      "intercept [38, 39, 36, 37, 37] 37.4 1.02\n",
      "\n",
      "1500\n",
      "COF [37, 37, 37, 36, 37] 36.8 0.4\n",
      "intercept [38, 39, 34, 38, 37] 37.2 1.72\n",
      "\n",
      "2000\n",
      "COF [36, 36, 38, 35, 37] 36.4 1.02\n",
      "intercept [39, 39, 34, 36, 37] 37.0 1.897\n",
      "\n",
      "2500\n",
      "COF [36, 37, 36, 37, 37] 36.6 0.49\n",
      "intercept [38, 38, 34, 37, 36] 36.6 1.497\n",
      "\n",
      "4000\n",
      "COF [37, 37, 34, 37, 38] 36.6 1.356\n",
      "intercept [38, 37, 34, 37, 36] 36.4 1.356\n",
      "\n",
      "6000\n",
      "COF [33, 36, 34, 36, 35] 34.8 1.166\n",
      "intercept [36, 36, 34, 36, 35] 35.4 0.8\n",
      "\n",
      "all\n",
      "COF [34, 34, 34, 34, 34] 34.0 0.0\n",
      "intercept [35, 35, 35, 35, 35] 35.0 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for point in epoints:\n",
    "    print(point)\n",
    "    for target in [\"COF\", \"intercept\"]:\n",
    "        n_features = [len(emodels_features[point][target][i]) for i in range(5)]\n",
    "        print(target, n_features, np.average(n_features), round(np.std(n_features), 3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2fb7e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COF\n",
    "target = \"COF\"\n",
    "COF_n_features = list() \n",
    "# original\n",
    "COF_n_features.append(len(omodels[\"everything\"][target][\"features\"]))\n",
    "\n",
    "# mix 50 \n",
    "for point in mpoints:\n",
    "    for i in range(5):\n",
    "        COF_n_features.append(len(mmodels_features[point][target][i]))\n",
    "    \n",
    "# everything \n",
    "for point in epoints:\n",
    "    for i in range(5):\n",
    "        COF_n_features.append(len(emodels_features[point][target][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad0c564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 32 - 45\n",
      "Average: 37.24752475247525; std: 2.905801437118781\n"
     ]
    }
   ],
   "source": [
    "# Number of features in various COF models\n",
    "print(f\"Range: {min(COF_n_features)} - {max(COF_n_features)}\")\n",
    "print(f\"Average: {np.average(COF_n_features)}; std: {np.std(COF_n_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e0b7bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept\n",
    "target = \"intercept\"\n",
    "intercept_n_features = list() \n",
    "# original\n",
    "intercept_n_features.append(len(omodels[\"everything\"][target][\"features\"]))\n",
    "\n",
    "# mix 50 \n",
    "for point in mpoints:\n",
    "    for i in range(5):\n",
    "        intercept_n_features.append(len(mmodels_features[point][target][i]))\n",
    "    \n",
    "# everything \n",
    "for point in epoints:\n",
    "    for i in range(5):\n",
    "        intercept_n_features.append(len(emodels_features[point][target][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8dc94ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 33 - 45\n",
      "Average: 37.0990099009901; std: 2.531015334537574\n"
     ]
    }
   ],
   "source": [
    "# Number of features in various intercept models\n",
    "print(f\"Range: {min(intercept_n_features)} - {max(intercept_n_features)}\")\n",
    "print(f\"Average: {np.average(intercept_n_features)}; std: {np.std(intercept_n_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd3c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
