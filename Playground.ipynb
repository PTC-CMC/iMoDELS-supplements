{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atools_ml.descriptors import rdkit_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COF_paths = dict()\n",
    "F0_paths = dict()\n",
    "COF_paths['pickle'] = 'random-forest/models/everything/nbins-10/set_0/COF_all.pickle'\n",
    "COF_paths['ptxt'] = 'random-forest/models/everything/nbins-10/set_0/COF_all.ptxt'\n",
    "F0_paths['pickle'] = 'random-forest/models/everything/nbins-10/set_0/intercept_all.pickle'\n",
    "F0_paths['ptxt'] = 'random-forest/models/everything/nbins-10/set_0/intercept_all.ptxt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(COF_paths['pickle'] ,'rb') as m: \n",
    "    COF_model = pickle.load(m)\n",
    "with open(COF_paths['ptxt'], 'rb') as f:\n",
    "    COF_features = pickle.load(f)\n",
    "with open(F0_paths['pickle'], 'rb') as m:\n",
    "    F0_model = pickle.load(m)\n",
    "with open(F0_paths['ptxt'], 'rb') as f:\n",
    "    F0_features = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_descriptors = pd.read_csv('data/raw-data/descriptors-ind.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_raw_descriptors(h_smiles, ch3_smiles, ind_descriptors):\n",
    "    '''Retrieve h_smiles and ch3_smiles descriptors from ind_descriptor.\n",
    "        \n",
    "    If parameters do not exist in ind_descriptors, calculate the parameters\n",
    "    from scratch (averagin over 1000 trials)\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    h_smiles : str\n",
    "        h_smiles string of the interested chemistry\n",
    "    ch3_smiles : str \n",
    "        ch3_smiles string of the interested chemistry\n",
    "    ind_descriptors : pd.Dataframe\n",
    "        Dataframe which contains the reference descriptors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tg_descriptors : dict\n",
    "    '''\n",
    "    import pandas as pd \n",
    "\n",
    "    final_desc_h_tg = dict()\n",
    "    final_desc_ch3_tg = dict()\n",
    "\n",
    "    tg_descriptors = dict()\n",
    "\n",
    "    if (h_smiles not in ind_descriptors) or ch3_smiles not in ind_descriptors:\n",
    "        print(f'Calculating chemical descriptors for {h_smiles} and {ch3_smiles}')\n",
    "        for i in range(1000):    \n",
    "            tmp_desc_h_tg = rdkit_descriptors(h_smiles)\n",
    "            tmp_desc_ch3_tg = rdkit_descriptors(ch3_smiles,\n",
    "                include_h_bond=True, ch3_smiles=ch3_smiles)\n",
    "\n",
    "            for key in tmp_desc_h_tg:\n",
    "                if key in final_desc_h_tg:\n",
    "                    final_desc_h_tg[key].append(tmp_desc_h_tg[key])\n",
    "                else:\n",
    "                    final_desc_h_tg[key] = [tmp_desc_h_tg[key]]\n",
    "            for key in tmp_desc_ch3_tg:\n",
    "                if key in final_desc_ch3_tg:\n",
    "                    final_desc_ch3_tg[key].append(tmp_desc_ch3_tg[key])\n",
    "                else:\n",
    "                    final_desc_ch3_tg[key] = [tmp_desc_ch3_tg[key]]\n",
    "        for key in final_desc_h_tg:\n",
    "            final_desc_h_tg[key] = np.mean(final_desc_h_tg[key])\n",
    "        for key in final_desc_ch3_tg:\n",
    "            final_desc_ch3_tg[key] = np.mean(final_desc_ch3_tg[key])\n",
    "\n",
    "        tg_descriptors[h_smiles] = final_desc_h_tg\n",
    "        tg_descriptors[ch3_smiles] = final_desc_ch3_tg\n",
    "        result = pd.DataFrame.from_dict(tg_descriptors)\n",
    "    else:\n",
    "        print(f'{h_smiles} and {ch3_smiles} already exist in ind_descriptors')\n",
    "        result = ind_descriptors[[h_smiles, ch3_smiles]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_descriptors(top_smiles, top_frac,\n",
    "                            bot_smiles, bot_frac,\n",
    "                            desc_df):\n",
    "    '''Consolidate h_smiles and ch3_smiles descriptors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    top_smiles : list\n",
    "        List of smiles strings of the top monolayer, each chemistry \n",
    "        need to be represented by 2 elements in a tuple, i.e. (h_smiles, ch3_smiles)\n",
    "    top_frac : list\n",
    "        List of fraction corresponding to the list of smiles in the top\n",
    "        monolyaer\n",
    "    bot_smiles : list\n",
    "        List of smiles strings of the bottom monolayer, each chemistry \n",
    "        need to be represented by 2 elements in a tuple, i.e. (h_smiles, ch3_smiles)\n",
    "    bot_frac : list\n",
    "        List of fraction corresponding to the list of smiles in the bottom\n",
    "        monolayer\n",
    "    desc_df : pd.DataFrame\n",
    "        DataFrame which contains individual descriptors of SMILES string \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    '''\n",
    "    \n",
    "    assert len(top_smiles) == len(top_frac)\n",
    "    assert len(bot_smiles) == len(bot_frac)\n",
    "    assert sum(top_frac) == 1 \n",
    "    assert sum(bot_frac) == 1 \n",
    "    to_drop = ['pc+-mean', 'pc+-min', 'pc--mean', 'pc--min']\n",
    "    with open('data/raw-data/feature-clusters.json', 'r') as f:\n",
    "        clusters = json.load(f) # this is a dict\n",
    "    shape_features = clusters['shape'] # a list from the clusters dict\n",
    "    top_desc = {'h': dict(), 'ch3': dict()}\n",
    "    bot_desc = {'h': dict(), 'ch3': dict()}\n",
    "    for key in desc_df.index:\n",
    "        top_desc['h'][key] = top_desc['ch3'][key] = 0\n",
    "        bot_desc['h'][key] = bot_desc['ch3'][key] = 0 \n",
    "        for i in range(len(top_smiles)):\n",
    "            top_desc['h'][key] += desc_df[top_smiles[i][0]][key] * top_frac[i]\n",
    "            top_desc['ch3'][key] += desc_df[top_smiles[i][1]][key] * top_frac[i]\n",
    "        for j in range(len(bot_smiles)):\n",
    "            bot_desc['h'][key] += desc_df[bot_smiles[j][0]][key] * bot_frac[j]\n",
    "            bot_desc['ch3'][key] += desc_df[bot_smiles[j][1]][key] * bot_frac[j]\n",
    "    \n",
    "    desc_h_df = pd.DataFrame([top_desc['h'], bot_desc['h']])\n",
    "    desc_ch3_df = pd.DataFrame([top_desc['ch3'], bot_desc['ch3']])\n",
    "                \n",
    "    desc_df = []\n",
    "    for i, df in enumerate([desc_h_df, desc_ch3_df]):\n",
    "        if i == 1:\n",
    "            hbond_tb = max(df['hdonors'][0], df['hacceptors'][1]) \\\n",
    "                       if all((df['hdonors'][0], df['hacceptors'][1])) \\\n",
    "                       else 0\n",
    "            hbond_bt = max(df['hdonors'][1], df['hacceptors'][0]) \\\n",
    "                       if all((df['hdonors'][1], df['hacceptors'][0])) \\\n",
    "                       else 0\n",
    "            hbonds = hbond_tb + hbond_bt\n",
    "            df.drop(['hdonors', 'hacceptors'], 'columns', inplace=True)\n",
    "        else:\n",
    "            hbonds = 0\n",
    "        means = df.mean()\n",
    "        mins = df.min()\n",
    "        means = means.rename({label: '{}-mean'.format(label)\n",
    "                              for label in means.index})\n",
    "        mins = mins.rename({label: '{}-min'.format(label)\n",
    "                            for label in mins.index})\n",
    "        desc_tmp = pd.concat([means, mins])\n",
    "        desc_tmp['hbonds'] = hbonds\n",
    "        desc_tmp.drop(labels=to_drop, inplace=True)\n",
    "        desc_df.append(desc_tmp)\n",
    "\n",
    "    df_h_predict = desc_df[0]\n",
    "    df_ch3_predict = desc_df[1]\n",
    "    df_h_predict = pd.concat([\n",
    "        df_h_predict.filter(like=feature) for feature in shape_features], axis=0)\n",
    "    df_ch3_predict.drop(labels=df_h_predict.keys(), inplace=True)\n",
    "\n",
    "    df_h_predict_mean = df_h_predict.filter(like='-mean')\n",
    "    df_h_predict_min = df_h_predict.filter(like='-min')\n",
    "    df_ch3_predict_mean = df_ch3_predict.filter(like='-mean')\n",
    "    df_ch3_predict_min = df_ch3_predict.filter(like='-min')\n",
    "    \n",
    "    df_predict = pd.concat([df_h_predict_mean, df_h_predict_min, \n",
    "                            df_ch3_predict_mean, df_ch3_predict_min,\n",
    "                            df_ch3_predict[['hbonds']]])\n",
    "   \n",
    "    return df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = consolidate_descriptors(top_smiles=[('C', 'CC'), ('N', 'CN')],\n",
    "                                 top_frac=[0.5, 0.5], \n",
    "                                 bot_smiles=[('C', 'CC')],\n",
    "                                 bot_frac=[1],\n",
    "                                 desc_df=ind_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_output = output.filter(COF_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15381959])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COF_model.predict(np.asarray(filtered_output).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75839098])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F0_model.predict(np.asarray(filtered_output).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
